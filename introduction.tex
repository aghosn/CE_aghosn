\section{Introduction}

%1. Applications evolved
%	1.1. Complicated multi-sourced piece of code.
%	1.2. Requirement for performance and security.
%	1.3. Deployed in new ways (e.g., cloud services)
%	
%2. Operating systems are too rigid.
%	2.1. Abstractions have not evolved much in the past decades.
%	2.2. Resource protection as well as management.
%	2.3. Leave little space for application specific logic.
%	2.4. Built in a way that requires them to be trusted.
%	
%3. Objective
%	3.1. Goals is to study designs that allow
%		3.1.1. separate protection from management.
%		3.1.2. Allow application specific management of resources.
%		3.1.3. Symmetric isolation mechanisms (e.g., protect guest from host).
%		3.1.4. Limit attack surface and rely on verification tools.
%	3.2. For that we study 3 different solutions
%		3.2.1 Hardware mechanism with SGX.
%		3.2.2. Kernel design.
%		3.2.3 Software kernel packaged for an application. 

%TODO remove afterwards
%TODO should define that in the paper we say guest for app or vm or anything that runs on top of the host, i.e., the kernel
\subsection{Applications evolved}

Modern applications for desktop PCs, mobile devices, and even web services incorporate multiple layers of software frameworks, interface with public APIs, and rely on external libraries, all of which might come from various, potentially untrusted, sources.
As a consequence of their intrinsic heterogeneity, most applications cannot be trusted and require strong isolation to prevent them from corrupting their host, or impacting other services running on the same system.
Sandboxing mechanisms are therefore an essential building block of today's systems: Cloud services run guest applications within containers or virtual machines, web browsers sandbox the JavasSript and web-applets executed while visiting web pages, and operating systems run untrusted applications in unprivileged mode.
In this classical hierarchical security model, the host is part of the trusted privileged software stack, and must be protected from the untrusted guest (application).
In other words, common sandboxes implement a single-sided isolation mechanism.
This model, unfortunately, presents two main concerns with regards to modern applications' requirements
\begin{enumerate*}
	\item sandboxing limits the application's performance by fixing rigid APIs and the implementation of underlying system services
	\item modern applications generate and process sensitive data that must be protected from a compromised or flawed host
\end{enumerate*}.
We successively develop both of these concerns in the following paragraphs.

Traditional operating systems

Even push further, provided abstractions do not work.


\adrien{Performance rigid APIs, kernel-by-pass etc., adding sandboxing is often very limiting}
\adrien{Design to reconciliate performance and security}
\adrien{Description of sandboxing}
\adrien{Unfortunately two main concerns: not bidirectional, and impact performance too}
Cloud or Microsoft or CIA

\subsection{Operating systems did not}
\adrien{Use the paper sent by Marios for everything that is related to POSIX abstractions and new layered application.
shift of paradigm where applications mostly interface with frameworks that either interact with os or by-pass it to re-implement some low-level features such as network.}

Meanwhile, operating system abstractions did not evolve.
Unix was designed in the seventeens, and is a source of inspiration for the current operating systems.
At the same time, it's the main source of inspiration for POSIX.
Problem is, these abstraction do not take into account new challenges.
That's why some papers break POSIX compatibility, or simply by-pass the kernel.
NEED EXAMPLES (IX can be one for dataplanes, LWC for more flexible memory management).\\

Kernel is responsible for resource protection and management at the same time.
While protection makes sense, i.e., role is to share the resources and ensure each unit some amount,
management seems to be bad, because the kernel is not aware of what the application needs.
A good example is garbage collection (okay I need to find a paper about this, maybe in the exokernel).\\

Finally kernels are all powerful. A compromised kernel can hurt any application.
While denial of service seems unavoidable, what might be a problem is data leakage, corruption, or highjacking of an application.
With more an more co-located applications on cloud services, this is a real problem.
Past efforts were made to protect host from guest, but now we actually want some guarantees the other way around as well.\\

\textit{Summary}: kernel abstractions did not follow the same evolution as applications.
There's a requirement for more liberty in resource management for the application, we want to separate protection from management.
At the same time, we also need to protect guest from host.

\subsection{Objectives}
 In this paper, we want to study existing designs that could better answer today's requirements imposed by the way applications are developped and deployed.
 We want the kernel to focus on protection rather than management.
 The application's knows best how to manage its resources, and should therefore be given access to such resources to do with as they want.
 By leaving the application with most of the management, we de-involve the kernel and hence get a better separation between kern and application, that allows to more easily provide a symmetric isolation/protection mechanisms from host to guest and guest to host.
 We also want to study how modern software tools and techniques can impact kernel design.
 How can we leverage software verification, static analysis and all of that in kernels? 
 C and C++ are the most used languages, we might want a completely type safe language.\\

 \textit{Summary:}This requires modifictions at several levels.
 We study a hardware solution, a kernel one, and a software one.
 We first present the following papers, and then the research proposal.


 
