\section{Unikernels: Library Operating Systems for the Cloud}
Traditionally, applications are deployed in the Cloud as virtual machines (VM).
A VM packs a complete operating system, such as Linux or Windows, that allows to run unmodified application processes.
Typically, a VM deployed in the Cloud can be viewed as a single-purpose appliance, i.e., it consists of a guest operating system running a main application that relies on smaller services running in parallel.
Due to the lack of standards for application configuration, VMs often run custom scripts as glue code to initialize the execution environment.

Although destined to execute a single main application, Cloud VMs are insufficiently specialized.
They contain an entire operating system image, distributed with some default services.
Apart from unnecessarily increasing the disk image size for this single-purpose appliance, hence requiring more resources to deploy and run the VM, the presence of unwanted default services increases the potential attack surface exposed to a malicious entity and threatens the VM's integrity.

The unikernel paper \cite{DBLP:conf/asplos/MadhavapeddyMRSSGSHC13} presents a new model to deploy applications in the Cloud that addresses the above-mentioned issues by radically specializing the Cloud application's image.
\emph{Unikernels} are small-size, sealed, single-purpose appliances entirely written in a high-level programming language, that can easily be configured and deployed over Cloud platforms.

\subsection{Design}
The unikernel revisits the idea of library operating systems (LibOS) by applying it to Cloud platforms.
A unikernel is a standalone kernel that encapsulates a single-purpose application destined to be deployed over the Cloud.
As such, unikernels execute on top of a VM hypervisor, e.g., Xen \cite{DBLP:conf/sosp/BarhamDFHHHN03}.
The advantages of targeting a virtualization platform instead of a custom kernel are twofold.
First, the hypervisor provides a fixed virtual hardware abstraction that alleviates the need to take into account heterogeneous hardware devices.
The hypervisor provides hardware drivers for a large number of devices and abstracts them away behind a fixed high-level interface.
Second, the hypervisor virtual abstraction facilitates both vertical and horizontal dynamic scaling.

Unikernels achieve aggressive specialization by relying on a single high-level programming language.
System libraries and the application are implemented in a common, statically typed, programming language, and compiled as a single specialized unikernel.
The compiler performs static analysis on the entire user stack and optimizes the whole system at once.
This enables to:
\begin{enumerate*}
	\item perform most of the appliance static configuration at compile time,
	\item reduce the final image's size, and
	\item improve the application's security
\end{enumerate*}, all of which without sacrificing performance.

Static configuration of a unikernel appliance happens at compile time.
As mentioned previously, standard VMs incur a non-negligible deployment overhead.
Custom scripts are executed to configure and start all services needed by the application, e.g., a database for a web server, and glue together independent packages or applications.
Unikernels, on the other hand, integrate all dependencies as libraries, compiled within the application itself.
Build parameters passed to the compiler enable static configuration, while dynamic configuration is achieved via specific function calls to the library.

Unikernels are small size highly compact binaries.
Since all the libraries are linked and compiled against the application itself, static analysis techniques such as dead-code elimination (DCE) can be applied to reduce the final image's size.
The authors claim that in most cases, the final binary's size is on the order of kilobytes, and hence easily deployable across the Internet.
Furthermore, in the context of Cloud platforms, where resources are rented, small size binaries consume less resources to host the program's code and data, and hence minimize expenses.

Unikernels leverage type-safety and static analysis and verification tools to improve the application's security.
%By eschewing backward compatibility and requiring the entire stack to be written in a single high-level typed programming language, unikernels can leverage type-safety as well as static analysis and verification tools to improve the application's security.
First, DCE reduces the attack surface exposed to a remote attacker system-wide.
Unused libraries as well as unreachable portions of code are not included in the final binary and cannot be used by an attacker to subvert the application.
Second, a unikernel executes entirely within a single address space and relies on the language's type safety to enforce access control and restrictions.
The single-address space model eases the integration of security techniques. 
For example, to prevent code injection, the unikernel is initialized such that no page mapping is both executable and writable.
To further protect against possible attacks, the unikernel can issue a \emph{seal} hypercall that prevents future page table modifications.
Other techniques and code instrumentation, e.g., address space randomization, stack canaries and guard pages, can also be added.

Unikernels, however, present some intrinsic limitations that need to be considered.
First, parts of the system, such as the garbage collector, are type-unsafe and require separate protection mechanisms.
Second, eschewing backward compatibility represents a daunting engineering challenge for application developers.
All libraries and protocols used by the application need to be rewritten in the same high-level language.
An alternate solution is to leverage interoperability at the network level.
Services that are not reimplemented in the chosen language can be encapsulated in separate VMs and communicate with the unikernel via standard network protocols.
Unfortunately, this technique increases resource usage, does not provide type-safety, and prevents system-wide optimizations.

%We report the evaluation results \cite{DBLP:conf/asplos/MadhavapeddyMRSSGSHC13} in the next section.

\subsection{Prototype and Evaluation}

A common argument against type-safe and memory managed programming languages is the overhead incurred by type checks and garbage collection.
Performance is critical to Cloud services tenants to achieve their service level objectives.
According to the authors, unikernels performances are comparable to standard VMs.

The authors evaluate a prototype unikernel implementation, called Mirage, that leverages OCaml system programming and static type system to produce appliances running on top of a Xen hypervisor \cite{DBLP:conf/sosp/BarhamDFHHHN03}.
A Mirage application is a standalone kernel, encapsulating a single process running in a 64-bits address space.
Parallelism within a VM is achieved via the OCaml Lwt cooperative threading library \cite{DBLP:conf/ml/Vouillon08}.
At the same time, a \emph{domainpoll} function enables to block the VM for external events and timeouts.
Lightweight threads enable to implement I/O protocols in a type-safe, non-blocking manner.
Network processing as well as storage I/Os are implemented as unikernel libraries under the control of the application and rely on a unified device driver model to read/write from/to a device.
Mirage applications contain a guest VM driver implemented in OCaml that communicates with a Xen backend driver via events and a shared memory page that holds requests and responses for device operations.
This shared memory ring is at the heart of every I/O in Mirage and allows device drivers to be implemented as OCaml libraries linked against the application.
The Mirage runtime memory management was specialized to dedicate a segment to these external I/O pages.

Mirage main features are evaluated against a set of microbenchmarks.
Compared to a Linux kernel running as a paravirtualized Xen domU, a Mirage appliance boots more than two times faster, enables the creation of 20 million threads twice as fast, incurs less jitter in thread timers thanks to the absence of user/kernel crossings, and performs network and storage I/O without significant overheads.

Mirage is then evaluated on more realistic applications, namely, a DNS server, an OpenFlow controller appliance, and a web server backed by a database.
In the remainder of this section, we focus on the DNS server evaluation that exhibits the advantages of relying on Mirage to deploy Cloud applications.
We note, however, that in all experiments, Mirage's performance is close to (or even better than) state-of-the-art implementations.

The Mirage DNS server application includes libraries for the network stack and an in-memory filesystem.
The authors compare the Mirage appliance to a state-of-the-art high performance implementation, NSD 3.2.10.
Adding memorization of responses enabled the Mirage appliance to reach a throughput lying between 75 and 80 kqueries/s.
In comparison, NSD reaches a maximal throughput of 70 kqueries/s.
Apart from the performance evaluation, the authors highlight the benefits of having a type-safe implementation of a DNS server.
Reportedly, the Bind software (a mature and popular DNS server) suffered from 40 important vulnerabilities in the past 10 years, mostly related to memory management errors and poor handling of exceptional cases.
Mirage's type-safety prevents this kind of error by design.
The DNS server Mirage appliance is a good example showing that type-safety, and more generally improved security, do not preclude performance. 

Finally, Mirage yields small size binary images, even for realistic applications.
For example, the Mirage DNS server image is 183.5 kB, while the equivalent Linux image, stripped down to the used components, is 462 MB.


\subsection{Discussion}

\input{unikernels_discussion_v2}