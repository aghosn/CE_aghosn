\section{Unikernels: Library Operating Systems for the Cloud}
%vm pack operating system + application.
%often dedicated to one purpose.
%no specialization
%glue code is used to run different services,
%overhead of everything that is not needed + security issue.

Traditionally, applications are deployed in the Cloud as virtual machines (VM).
A VM packs a complete operating system, such as Linux or Windows, that allows to run unmodified application processes.
Typically, a VM run in the Cloud can be viewed as a single-purpose appliance, i.e., it consists of a guest operating system running a main application, e.g., a database or web server, that relies on smaller services running in parallel.
Due to the lack of standards for application configuration, VMs often run custom scripts as glue code to initialize the execution environment.

Although destined to execute a single main application, Cloud VMs are insufficiently specialized.
They contain an entire operating system image, distributed with some default services.
Apart from unnecessarily increasing the disk image size for this single-purpose appliance, hence requiring more resources to deploy and run the VM, the presence of unwanted default services increases the potential attack surface exposed to a malicious entity and threatens the integrity of the VM.

The Unikernel paper[CITE] presents a new model to deploy applications in the Cloud that addresses the above-mentioned issues by radically specializing the Cloud application's image.
\emph{Unikernels} are small sized sealed single-purpose appliances entirely written in a high-level programming language, that can easily be configured and deployed over cloud platforms.


\subsection{Design Principles}


% 1. Unikernel libOS revisited.
% 	Different than the exokernel, runs on top of a hypervisor, such as Xen.
% 	Why abstraction from hardware is good? Because don't have to write the drivers and can run on the Cloud.
% 2. Unikernels go further than previous libOSes by fully specializing the entire user stack. The libOS and the application are compiled together to yield a standalone kernel to schedule on top of the hypervisor.
% 	Leveraging high-level PL allows to have static type-safety, and use PL tools such as software verification, dead-code elimination.
% 3. Configuration and Deployment
% 	static configuration.

The Unikernel revisists the idea of library operating systems (libOS) by applying it to Cloud platforms.
A unikernel is a standalone kernel that encapsulate a single-purpose application destined to be deployed over the Cloud.
As such, unikernels execute on top of a VM hypervisor, e.g., Xen[CITE].
The advantages of targeting a virtualization platform instead of a custom kernel are twofold.
First, the hypervisor provides a fixed virtual hardware abstraction that alleviates the need to take into account heterogeneous hardware devices.
The hypervisor provides hardware drivers for a large number of devices and abstracts them away behind a fixed high-level interface.
Second, the hypervisor virtual abstraction facilitates both vertical and horizontal dynamic scaling.

% Agressive specialization.
% Via aggressive specialization, achieve:
% 1. Small size compact images.
% 2. Configuration work is taken care of at compile time.

Unikernels achieve aggressive specialization by relying on a single high-level programming language.
System libraries and the application are implemented in a common, statically typed, programming language, and compiled as a single specialized unikernel.
The compiler performs static analysis on the entire user stack and optimizes the whole system at once.
This enables to:
\begin{enumerate*}
	\item perform most of the appliance static configuration at compile time,
	\item reduce the final image's size, and
	\item improve the application's security
\end{enumerate*}, all of which without sacrificing performance.

Static configuration of a unikernel appliance happens at compile time.
As mentioned previously, standard VMs incur a non-negligible deployment overhead.
Custom scripts are executed to configure and start all services needed by the application, e.g., a database for a web server, and glue together independent packages or applications.
Unikernels, on the other hand, integrate all dependencies as libraries, compiled within the application itself.
Build parameters passed to the compilation configuration enable static configuration, while dynamic configuration is achieved via specific function calls to the library.

Unikernels are highly specialized and compact binaries.
Since all the libraries are linked and compiled against the application itself, static analysis techniques such as dead-code elimination (DCE) can be applied to reduce the final image's size.
The authors claim that in most cases, the final binary's size is on the order of kilobytes, and hence easily deployable across the Internet.
Furthermore, in the context of Cloud platforms, where resources are rented, small size binaries consume less resources to host the program's code and data, and hence minimize expenses.

By eschewing backward compatibility and requiring the entire stack to be written in a single high-level typed programming language, unikernels can leverage type-safety and static analysis and verification tools to improve the application's security.
First, DCE reduces the attack surface exposed to a remote attacker system-wide.
Unused libraries as well as unreachable portions of code are not included in the final binary and cannot be leveraged by an attacker to subvert the application.
Second, a unikernel executes entirely within a single address space and relies on the language's type safety to enforce access control and restrictions.
The single-address space model eases the integration of security techniques. 
For example, to prevent code injection, the unikernel is initialized such that no page mapping is both executable and writable.
To further protect against possible attacks, the unikernel can issue a \emph{seal} hypercall, that prevents future page table modifications.
Other techniques and code instrumentation, e.g., address space randomization, stack canaries and guard pages, can also easily be added.

While type safety and system-wide optimizations are attractive, unikernels represent a daunting engineering challenge.
All libraries and protocols used by the application need to be rewritten in the same high-level language.
An alternate solution is to leverage interoperability at the network level.
Services that are not reimplemented in the chosen language can be encapsulated in separate VMs and communicate with the unikernel via standard network protocols.
Unfortunately, this technique increases resource usage and prevents system-wide optimizations.
Finally, parts of the system, such as the garbage collector, are type-unsafe and still require to be protected against. 

A common argument against type-safe and memory managed programming languages is the overhead incurred by type checks and garbage collection.
Performance is critical to Cloud services renters to achieve their service level objectives.
According to the authors, unikernels performances are comparable to standard VMs.
We report the evaluation results presented in [CITE] in the next section.

\subsection{Prototype and Evaluation}
%implementation called Mirage.
%Implemented in OCaml
%Hypervisor is Xen.
%Single process, threading achieved via lwthreads part of the language.
%typed protocol I/O give details from p465.
%Language runtime slightly modify, special support for device drivers based on I/O (not sure if going to talk about it).
%
%Evaluation performs microbenchmarks, DNS Server for safe network stack, Openflow control appliance, web server and database (storing and networking), and respective sizes.
%
%Boot time: less than half time required by linux debian running apache 2 in paravirtualized mode.
%Modifying how Xen builds domains enables to reboot the machine in less than 50 milliseconds.
%
%threads creation: better than pv and native. Creating 20 millions is more than twice faster in mirage os than pv, and noticeably faster than native. heap allocation.
%also more precised thread timers, mostly due to no user/kernel space crossings
%
%Net + Storage
% 10% overhead for mirage due to type safety.
% TCPv4 comparison on par with Linux.
The authors evaluate a prototype evaluation of unikernels, called Mirage, that leverages OCaml system programming and static type system to produce appliances running on top of a Xen[CITE] hypervisor.
A Mirage application is a standalone kernel, encapsulating a single process running in a 64-bit address space.
Concurrency within a VM is achieved via the OCaml Lwt cooperative threading[CITE] library.
At the same time, a \emph{domainpoll} function enables to block the VM for external events and timeouts.
Lightweight threads enable to implement I/O protocols in a type-safe, non-blocking manner.
Network processing as well as storage I/O are implemented as unikernel libraries under the control of the application that rely on a unified device driver model to read/write from/to a device.
Mirage applications contain a guest VM driver implemented in OCaml that communicates with a Xen backend driver via events and a shared memory page that holds requests and responses for device operations.
This shared memory ring is at the heart of every I/O in Mirage and allows device drivers to be implemented as OCaml libraries linked against the application.
The Mirage runtime memory management was specialized to dedicate segment to these external I/O pages.

Mirage's performance evaluation consists in microbenchmarks, to evaluate standalone features such as boot time and the network stack, and more realistic applications, namely a DNS server, and Openflow appliance, and a web server backed by a database.
We briefly report the results from[CITE].

Mirage appliances exhibit satisfactory performance results in the microbenchmark evaluation.
The Mirage image time to boot is more than twice smaller than an equivalent Linux kernel running as a paravirtualised Xen domU executing a similar application.
Regarding thread creation, Mirage manages to create 20 millions of threads more than twice faster than the paravirtualized linux, and slightly faster than linux running natively.
Surprisingly, the single address space model used by Mirage allows less jitter in thread timers than linux-based configurations, mostly due to the absence of user/kernel crossings.
Finally, the evaluation of the TCPv4 stack implementation in Mirage shows that it performs similarly to the Linux 3.7 TCPv4 one, while providing a type-safe implementation of the protocol.


\subsection{Discussion}
%\subsection{Overview}
%%TO SAY
%%Keywords: Specialization (of the kernel itself)
%%1. Goal is to have secured, small sized, efficient applications easy to deploy in cloud.
%%2. The application is the kernel. Strip down and seal the app to only what is needed.
%%3. Relies on PL and compiler techniques, e.g., static analysis, static type-safety etc.
%%4. Single address space !!! have to put that somewhere.
%\adrien{When talking about Mirage, say single process for a dedicated virtual CPU. domainpoll to block on event.}
%
%This should be a high level overview of the paper.
%
%\textit{Unikernels} are defined as small sized sealed single-purpose appliances that can easily be deployed over cloud services.
%More specifically, a unikernel encapsulate an application's logic as well as the required system libraries and language runtime.
%However, unlike regular general-purpose VMs, unused functionalities are stripped-away at compile-time therefore yielding a small %sized bootable image while reducing the potential attack surface exposed by said image.\\%
%
%Describe the overall architecture and design.\\
%
%\subsection{Specialization through a unified common language.}
%The application is the OS.
%This goes further than before.\\
%
%Specialising benefits are smaller deployable things.
%A common lower level interface that relies on the supervisor.
%Smaller attack surface.
%Reconfiguration require re-compilation so hard to modify behaviour?\\
%
%Single high level language means that we can leverage modern techniques, e.g. type safety, static analysis, compiler %optimizations to boost performance.%
%At the same time, single address sp%ace is enough because we have the functionalities from the language that act as ba%rriers.
%
%\subsection{Evaluation}
%TODO: redac this\\
%
%Main goals and claims: since supposed to be deployed on the cloud, both size and boot time are relevant.
%This is evaluated qualitatively by comparing LOCs between unikernels and VMs, and by measuring boot time required when deploying %the appliances.%
%Result is that %can boot in less than 50 ms (how does it compare to Linxu?)\\%
%
%Threading is efficient because no kernel and user space separation, hence avoid the mode switch overheads.\\
%
%Network and Storage type safety does not introduce significant delays.
%Thanks to single address space, 0-copy for receive so faster.
%Transmission is, however, slower because requires extra cpu processing (high level language).\\
%
%Application is DNS.
%
%\subsection{Discussion}
%
%Comparison with exokernel: different approach regarding the abstraction level.
%Still trusts the hypervisor, could we use the SGX to protect it somehow?
%Argument that hypervisor enables to get compatibility with drivers is good, but still need to reimplement all the system %libraries...%
%Still suffer%s from the same problems as any LibOS, you need to reimplement the libraries.%
%Other proble%m is that you limit the flexibility by requiring them to be implemented in OCaml.%
%Compatibilit%y with other applications is ensured by having a network communication between th%e appliance and a VM that ru%ns the %service.%
%Not good% because shared memory etc. is not really straight forward.\\
%
%What is better than exokernel? 
%The fact that we can rely on high-level pl tools like verification, dead-code elimination etc.
%Packageable (which is not really the case for an app in exokernel and not a considered concern).\\
%
%What is not as good?
%Everything needs to be implemented in OCaml, because we have the runtime environment and all of that.
%In exokernel, you have an interface, and it could be enough to somehow communicate with it.\\
%
%What is bad as well?
%Can you actually snapshot an appliance and migrate it?
%Check in the paper if this is the case because I'm really not sure.
%